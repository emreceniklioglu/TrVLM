## ğŸ§  TrVLM Nedir?
TrVLM, SigLIP gÃ¶rsel kodlayÄ±cÄ±sÄ± ile GPT2-large TÃ¼rkÃ§e dil modelini birleÅŸtiren Ã§ok modlu (multimodal) bÃ¼yÃ¼k bir dil modelidir. GÃ¶rselleri anlamlandÄ±rarak doÄŸal TÃ¼rkÃ§e metin Ã¼retimi yapabilen bu model, hem gÃ¶rsel aÃ§Ä±klama hem de gÃ¶rsel soru-cevap gÃ¶revlerini yerine getirebilecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## ğŸ”§ GeliÅŸtirme SÃ¼reci
1ï¸âƒ£ Tek Modalite Ã–n EÄŸitimi
Modelin her bileÅŸeni sÄ±fÄ±rdan eÄŸitilmemiÅŸ, yerine gÃ¼Ã§lÃ¼ Ã¶n-eÄŸitimli modeller entegre edilmiÅŸtir:

GÃ¶rsel kodlayÄ±cÄ±: google/siglip-base-patch16-224

Dil modeli: ytu-cosmos/Turkish-Llama-8b-Instruct-v0.1

2ï¸âƒ£ Ã–zellik Uyarlama
LLaVA eÄŸitim yaklaÅŸÄ±mÄ± izlenerek, sadece gÃ¶rsel projektÃ¶r katmanÄ± 500K gÃ¶rsel-metin Ã§ifti ile eÄŸitilmiÅŸtir. Bu sayede gÃ¶rsel ve dil temsilleri birleÅŸtirilerek uyumlu hale getirilmiÅŸtir.

Huggingface Veriseti : emrecn/Predataset

3ï¸âƒ£ GÃ¶rev Spesifik EÄŸitim
UyumlaÅŸtÄ±rÄ±lan model, Ã¼Ã§ temel gÃ¶rev iÃ§in ayrÄ± ayrÄ± eÄŸitilmiÅŸtir:

KÄ±sa AÃ§Ä±klama

DetaylÄ± AÃ§Ä±klama

GÃ¶rsel Soru-Cevaplama (VQA)

EÄŸitim iÃ§in, 1 milyondan fazla resim-soru-cevap Ã¼Ã§lÃ¼sÃ¼nÃ¼ iÃ§eren bir veri kÃ¼mesi kullanÄ±lmÄ±ÅŸtÄ±r.

Huggingface Veri setleri :

KÄ±sa : emrecn/newveri ,

Uzun : emrecn/longdataset

Vqa : berkanbucak/finetunevqa

---

## ğŸ§© Model Details

### Model Description

- **Developed by:** Emre CeniklioÄŸlu, Berkan Bucak, Cihan Deniz Ekiz
- **Affiliation:** Ankara University - Computer Engineering Department  
- **Model Type:** Multi-modal Encoder-Decoder (Image-Text-to-Text), Causal Language Model  
- **Language(s):** Turkish (`tr`)
---

## ğŸ§© KullanÄ±m AlanlarÄ± â€“ TrVLM
AÅŸaÄŸÄ±da, TrVLM Ã§ok modlu gÃ¶rsel-dil modelinin doÄŸrudan, dolaylÄ± ve alan dÄ±ÅŸÄ± kullanÄ±m senaryolarÄ± aÃ§Ä±klanmÄ±ÅŸtÄ±r.

### âœ… DoÄŸrudan KullanÄ±m AlanlarÄ±
ğŸ”¹ KÄ±sa AÃ§Ä±klama (Short Captioning)
Bu gÃ¶revde TrVLM, gÃ¶rselin hÄ±zlÄ± ve Ã¶zlÃ¼ bir aÃ§Ä±klamasÄ±nÄ± yapar. KullanÄ±cÄ±lar modele ÅŸu tÃ¼r prompt'lar verebilir:

"KÄ±saca aÃ§Ä±kla", "GÃ¶rseli Ã¶zetle", "Ã‡ok kÄ±sa Ã¶zetle"

Model, gÃ¶rselin genel iÃ§eriÄŸini kÄ±sa bir ÅŸekilde ifade eder.
Not: Bu gÃ¶rev iÃ§in model, dÃ¼ÅŸÃ¼k halÃ¼sinasyon eÄŸilimindedir ve yÃ¼ksek doÄŸrulukla Ã§alÄ±ÅŸÄ±r. FarklÄ± Ã¼retim parametreleriyle Ã§Ä±ktÄ±larÄ±nÄ±zÄ± Ã¶zelleÅŸtirebilirsiniz.

ğŸ”¹ DetaylÄ± AÃ§Ä±klama (Detailed Captioning)
Bu gÃ¶revde TrVLM, gÃ¶rseldeki tÃ¼m detaylarÄ± daha kapsamlÄ± ÅŸekilde aÃ§Ä±klamaya Ã§alÄ±ÅŸÄ±r. AÅŸaÄŸÄ±daki gibi promptâ€™lar verilebilir:

"DetaylÄ± aÃ§Ä±kla", "GÃ¶rseli Ã§ok detaylÄ± anlat"

Model genellikle baÅŸarÄ±lÄ± cevaplar Ã¼retir ancak zaman zaman gÃ¶rselde olmayan detaylar hayal edebilir (halÃ¼sinasyon).
Not: Bu gÃ¶revin Ã§Ä±ktÄ±larÄ±nda dikkatli deÄŸerlendirme Ã¶nerilir.

ğŸ”¹ GÃ¶rsel Soru-Cevaplama (Visual Question Answering)
Model, verilen bir gÃ¶rsele iliÅŸkin sorulara yanÄ±t verir. Ã–rnek promptâ€™lar:

"Bu gÃ¶rselde kaÃ§ kiÅŸi var?", "Adam ne yapÄ±yor?", "Bu araba ne renk?"

Not: Bu gÃ¶revde model baÅŸarÄ±lÄ± olsa da bazen gÃ¶rselde olmayan cevaplar Ã¼retme eÄŸilimindedir. Ãœretim ayarlarÄ± ile Ã§Ä±ktÄ±lar kontrol altÄ±na alÄ±nabilir.

### ğŸš« Alan DÄ±ÅŸÄ± KullanÄ±m SenaryolarÄ±
AÅŸaÄŸÄ±daki durumlar iÃ§in model uygun deÄŸildir:

Ã‡ok turlu diyaloglar / chat senaryolarÄ±: TrVLM geÃ§miÅŸ bilgiyi tutmaz. Ã‡ok turlu konuÅŸmalar iÃ§in eÄŸitilmemiÅŸtir.

Ã‡oklu gÃ¶rsel karÅŸÄ±laÅŸtÄ±rma: AynÄ± anda birden fazla gÃ¶rsel giriÅŸi desteklemez.

OCR, Segmentasyon, Ã‡oklu Obje TanÄ±ma: Bu gÃ¶revler iÃ§in model eÄŸitilmemiÅŸtir. 

---

## âš ï¸ Bias, Risks, and Limitations

Model, internetten toplanmÄ±ÅŸ TÃ¼rkÃ§e metin ve gÃ¶rsellerle eÄŸitilmiÅŸtir. DolayÄ±sÄ±yla:

- Ã–nyargÄ±lÄ±, toplumsal hassasiyet iÃ§eren ifadeler Ã¼retme riski taÅŸÄ±r.
- GÃ¶rsel iÃ§eriÄŸi yanlÄ±ÅŸ yorumlayabilir.
- GerÃ§eklikten uzak yanÄ±tlar verebilir.
---

## ğŸš€ How to Get Started with the Model

TrVLM modelini denemenin en kolay yolu, tÃ¼m gerekli dosyalarÄ± indirip inference.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmaktÄ±r. Bu dosya, Gradio tabanlÄ± bir web arayÃ¼zÃ¼ baÅŸlatarak, kullanÄ±cÄ±larÄ±n modele kolayca gÃ¶rsel ve metin giriÅŸi yaparak Ã§Ä±ktÄ±larÄ± test etmesini saÄŸlar.

ğŸ”§ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:

AÅŸaÄŸÄ±daki bileÅŸenleri indirmeniz gerekmektedir:

base model aÄŸÄ±rlÄ±klarÄ± 

fine-tuned LoRA adapter aÄŸÄ±rlÄ±klarÄ±

ğŸ’¾ TÃ¼m bu dosyalar aÅŸaÄŸÄ±daki Google Drive baÄŸlantÄ±sÄ±nda mevcuttur:

ArdÄ±ndan !python inference.py komutu ile inference ortamÄ±nÄ± baÅŸlatabilirsiniz:

## ğŸ‹ï¸ Training Details

âš™ï¸ Training Procedure

Pretrain: Sadece gÃ¶rselden metne projeksiyon katmanÄ± eÄŸitildi

BaÅŸarÄ±: Model, gÃ¶rsel-metin eÅŸleÅŸtirmede temel yetkinlik kazandÄ±.

| Ã–zellik               | DeÄŸer                    |
| --------------------- | ------------------------ |
| **Veri SayÄ±sÄ±**       | 575K gÃ¶rÃ¼ntÃ¼-metin Ã§ifti |
| **Global Batch Size** | 16                      |
| **Learning Rate**     | 2e-4                   |
| **Epochs**            | 2                        |
| **Max Length**        | 256                     |
| **Weight Decay**      | 0.1                     |

DonanÄ±m: 1x NVIDIA A100 GPU (Google Colab), 4 saat sÃ¼re.

Fine-tune: 1. Ã‡ok GÃ¶revli Fine-Tuning (Multitask Fine-Tuning)

AmaÃ§: Modelin birden fazla gÃ¶revde (VQA, kÄ±sa/uzun aÃ§Ä±klama Ã¼retme) aynÄ± anda performansÄ±nÄ± artÄ±rmak.

Dondurulan BileÅŸenler: SIGLIP encoder ve Turkish LLaMA'nÄ±n Ã§oÄŸu katmanÄ± (sadece projeksiyon katmanÄ± ve dil modelinin Ã¶nemli katmanlarÄ± eÄŸitildi).

LoRA (Low-Rank Adaptation): Dil modelinin dikkat katmanlarÄ±na hafif adaptasyon uygulandÄ±.

| Ã–zellik               | DeÄŸer                                   |
| --------------------- | --------------------------------------- |
| **Veri SayÄ±sÄ±**       | 1.1M gÃ¶rsel + talimat + cevap Ã¼Ã§lÃ¼sÃ¼    |
| **Global Batch Size** | 8                                       |
| **Learning Rate**     | 5e-5                                    |
| **Epochs**            | 1                                       |
| **Max Length**        | 256                                     |
| **Weight Decay**      | 1e-6                                    |

2. KÄ±sa AÃ§Ä±klama iÃ§in Fine-Tuning
   
AmaÃ§ : Multitask modelin kÄ±sa aÃ§Ä±klamalardaki baÅŸarÄ±sÄ±nÄ± daha da artÄ±rmak.

Strateji: Tam fine-tuning yerine LoRA kullanÄ±ldÄ±.

Adapte Edilen Katmanlar: Dil modelinin dikkat mekanizmalarÄ± ve projeksiyon katmanÄ±.

Avantaj: Modelin kÄ±sa aÃ§Ä±klama Ã¼retme yeteneÄŸini arttÄ±rmak.

| Ã–zellik               | DeÄŸer                                   |
| --------------------- | --------------------------------------- |
| **Veri SayÄ±sÄ±**       | 510k kÄ±sa aÃ§Ä±klama veri seti |
| **Global Batch Size** | 8                                       |
| **Learning Rate**     | 1e-5                                    |
| **Epochs**            | 3                                       |


ğŸ–¥ï¸ Compute Infrastructure
GPU: NVIDIA A100 (Colab Pro+)

Frameworks: PyTorch, Hugging Face Transformers

Transformers

ğŸ“Š Evaluation

### **1. Metrik TabanlÄ± DeÄŸerlendirme**
Model, 4 farklÄ± gÃ¶rev tÃ¼rÃ¼nde (Multitask, Uzun AÃ§Ä±klama, VQA, KÄ±sa AÃ§Ä±klama) 8 metrikle test edilmiÅŸtir. KullanÄ±lan metrikler:

#### **Performans Tablosu**:
| **Metrik**           | **Multitask** | **Uzun AÃ§Ä±klama** | **VQA**      | **KÄ±sa AÃ§Ä±klama** |
|----------------------|---------------|-------------------|--------------|-------------------|
| **ROUGE-1**          | 0.2494        | 0.3177            | 0.3533       | **0.4816**        |
| **ROUGE-2**          | 0.1311        | 0.0907            | 0.1842       | **0.2835**        |
| **ROUGE-L**          | 0.2049        | 0.1901            | 0.3074       | **0.4164**        |
| **BLEU**             | 0.0352        | 0.0063            | 0.0555       | **0.0976**        |
| **METEOR**           | 0.1461        | 0.0824            | 0.2174       | **0.2921**        |
| **BERT Precision**   | 0.5546        | 0.5252            | 0.6676       | **0.6824**        |
| **BERT Recall**      | 0.1461        | **0.5771**        | 0.6335       | 0.6575            |
| **BERT F1**          | 0.5110        | 0.5493            | 0.6462       | **0.6687**        |


---

### **2. GPT-4o Hakem DeÄŸerlendirmesi**
100 Ã¶rnek Ã¼zerinde GPT-4o'nun insan benzeri deÄŸerlendirmesi (0-10 arasÄ± puanlama):

| **Kriter**                     | **Puan** |
|-------------------------------|----------|
| **Talimat Uyumu**             | 6.25     | 
| **GÃ¶rsel-Metin TutarlÄ±lÄ±ÄŸÄ±**  | 7.30     | 
| **Anlamsal DoÄŸruluk**         | 6.80     | 
| **YaratÄ±cÄ±lÄ±k & Ã‡eÅŸitlilik**  | 5.50     | 
| **GENEL ORTALAMA**            | 6.46     |

---

### **3. Kritik SonuÃ§lar ve Ã–neriler**
#### **BaÅŸarÄ±lar**:
1. âœ… **KÄ±sa AÃ§Ä±klamada SÄ±nÄ±f Lideri**: TÃ¼m metriklerde en yÃ¼ksek skor.
2. âœ… **GÃ¶rsel-Metin TutarlÄ±lÄ±ÄŸÄ±**: GPT-4o ile 7.3 puan (projenin ana gÃ¼cÃ¼).
3. âœ… **DÃ¼ÅŸÃ¼k Kaynak VerimliliÄŸi**: 1x A100 GPU ile 4 saatlik pretrain.

#### **Performans Ã–zet Tablosu**:
| **GÃ¶rev**         | **GÃ¼Ã§lÃ¼ YÃ¶nler**       | **ZayÄ±f YÃ¶nler**         | **Ä°yileÅŸtirme Ã–nceliÄŸi** |
|-------------------|------------------------|--------------------------|--------------------------|
| KÄ±sa AÃ§Ä±klama     | ROUGE, BERTScore       | -                        | â­ (En iyi)              |
| VQA               | Anlamsal doÄŸruluk      | Kelime seÃ§imi hatalarÄ±   | â­â­                      |
| Uzun AÃ§Ä±klama     | BERT Recall            | AkÄ±cÄ±lÄ±k ve zenginlik    | â­â­â­ (Acil)              |
| Multitask         | Denge                  | GÃ¶rev Ã§akÄ±ÅŸmasÄ±          | â­â­                      |

**SonuÃ§**: Model, TÃ¼rkÃ§e VLM'ler arasÄ±nda **kÄ±sa aÃ§Ä±klama ve VQA'da baÅŸarÄ±lÄ±**, ancak uzun metin Ã¼retimi ve yaratÄ±cÄ±lÄ±kta geliÅŸime aÃ§Ä±k.

ğŸ§  Model Architecture and Objective

GÃ¶rsel encoder: SigLIP (Google)

Projeksiyon katmanÄ±: MLP (768 â†’ 4096)

LLM: Turkish LLaMA 8B

ğŸ™‹ Model Card Contact

Emre CeniklioÄŸlu â€“ GitHub 

Mail: emreceniklioglu11@gmail.com


